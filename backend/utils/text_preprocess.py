def preprocess_text(text):
    # Mock text preprocessing: tokenization, embedding
    # In a real scenario, this would use Transformers tokenizer
    return {"tokens": len(text.split()), "embedding": [0.1] * 10, "text": text}
